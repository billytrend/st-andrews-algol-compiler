\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{svg}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{xcolor}
\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

\lstdefinelanguage{javascript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
   language=JavaScript,
   backgroundcolor=\color{lightgray},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b,
   postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{red}\hookrightarrow\space}}
}

% Title page
% Containing the title of the project, the names of the student(s), "University of St Andrews" and the date of submission. You may add the name of your supervisor if you wish.

\title{St Andrews Algol to Javascript compiler project}
\author{William Trend}
\date{February 2016}

\begin{document}

\maketitle

\begin{abstract}
% Outline of the project using at most 250 words.
This project contains the implementation and documentation of a compiler that accepts St Andrews Algol (S-Algol) programs and produces analagous javascript programs. It provides both a tool for the preservation the language and an investigation into how languages have devloped between 1979 and 2016.

\end{abstract}

\section{Declaration}
I declare that the material submitted for assessment is my/our* own work except where credit is explicitly given to others by citation or acknowledgement. This work was performed during the current academic year except where otherwise stated.

The main text of this project report is TODO words long, including project specification and plan.

In submitting this project report to the University of St Andrews, I give permission for it to be made available for use in accordance with the regulations of the University Library. I also give permission for the title and abstract to be published and for copies of the report to be made and supplied at cost to any bona fide library or research worker, and to be made available on the World Wide Web. I retain the copyright in this work.

\section{Introduction}
% Describe the problem you set out to solve and the extent of your success in solving it. You should include the aims and objectives of the project in order of importance and try to outline key aspects of your project for the reader to look for in the rest of your report.

The aim of this project is to produce a compiler for S-Algol to Javascript to preserve the language for people interested in its history. It quickly became clear during development that actually a the task of building a 'compiler' is not a closed specfication. There is an infinite amount of work that may be put into writing a compiler (in the case of the optimisation stage of a compiler, this is literally true since the best optimiser would be able to delete infinite loops in code which would be a solution to the halting problem, a problem that is known to be unsolvable). As such, it was important to place more concrete boundaries on the functionality of the compiler. The features that have been implemented are listed below.

\begin{enumerate}
\item A lexer and parser for the full S-Algol according to the grammar (TODO: add grammar to appendix)
\item Code generation for most of the language features (procedures, variables, operations, vectors and structs)
\item Checking for scope errors
\item Checking for various possible type errors
\item A command-line interface for the compiler
\item A test suite for individual parts of the compiler tool chain and hollistic end-to-end testing
\end{enumerate}

A considerable amount of time for the project was spent doing archaeology into the various pieces of documentation that were available. There were problems both with conflicting documentation and documentation that was too sparse. Furthermore, the source of the original S-Algol compiler is difficult to read for people that are more used to modern languages - especially since there are no syntax highlights available for it.


\section{Context survey}
% Surveying the context, the background literature and any recent work with similar aims. The context survey describes the work already done in this area, either as described in textbooks, research papers, or in publicly available software. You may also describe potentially useful tools and technologies here but do not go into project-specific decisions.

\subsection{Historical significance of S-algol}

The St Andrews Algol language (S-algol) was designed as part of Ron Morrison's PHD thesis in 1979. It was subsequently use to teach programming to undergraduates in the university computer science department until 1999. It was also used at the local Madras college.

S-algol is a member of a family of languages known as the 'ALGOLs'. The name of the family references their ability to easily abstract algorithms. In the seminal paper of S-algol, Morrison highlight 5 features of programming languages that 'roughly' classify the ALGOLs:

\begin{enumerate}
    \item "Scope rules and block structure"
    \item "Abstraction facility"
    \item "Compile time type checking"
    \item "Infinite store"
\end{enumerate}

Given this description, it is clear that many modern languages could arguably be described as being part of the ALGOL family. Indeed it seems that this is so much the case that it is no longer particularly useful to classify languages as ALGOLs (TODO: maybe talk abot algol lisp dichotemy). Certainly there are no modern languages that are not influenced heavily by ALGOL programs. Reynolds defines the ALGOL family in 1981 to be "a conceptual universe for language design that one hopes will encompass languages far more general than its progenitor" \cite{reynolds}. This codifies the intention for the class of languages to be as inclusive as possible. 

In the introduction to his PHD thesis, Morrison offers a thoughtful commentary on the problems of programming language design and the ways in which S-Algol intends to solve them. In this spirit, this report shall provide a similar analysis with direct reference to S-Algol and modern languages. This historical continuity provides some of the motivation for this project. It is possible to gain insight into language development by observing the difference between S-algol and languages of today. The differences were made very clear during the development of this project since it is written in Typescript - a language released in 2012 \cite{jsconf}. Typescript has a very modern syntax and semantics and represents exactly how S-algol compares to the cutting edge of programming language design. Further motivation for this language choice will be explored in the 'Design' chapter.

\subsection{Javascript as a Tool for Preservation}

The bulk of this project involves implementing a compiler that will take some S-algol program as input and output a valid Javascript program which can be run in a browser or on a server. The following aspects of Javascript were considered.

\paragraph{Performance} Since the main aim of this project is simply to be able to execute code written in S-algol, performance is not particularly important. However, Javascript performance is known to be constantly improving: using certain techniques, Mozilla has managed to execute subsets of the languages at near native performance \cite{moz}. The performance of Javascript is at least good enough for this project. 

\paragraph{Portability} The principal aspect of Javascript that caused it to stand out as the most viable option for this project was portability. It is absolutely possible that using a compiled programming language such as C might be more performant than using Javascript, however, these languages are often very architecture dependent. C may need to be compiled especially for each architecture that it is to be run on. Javascript can be dsitributed as source and executed on any platform. Furthermore, executing C often requires elevated privileges since it can perform operations that might be undesirable. Javascript runs in a browser sandbox which means that it is encapsulated from the host operating system, preventing it from executing maliciously.

\paragraph{Ubiquity} Access to the websites is the most basic function of any consumer electronic device sold today. Since Javascript is the programming language of the web, this means that almost every every computing device sold today can run the platform at least through a web-browser. Some devices offer Javascript absolute first-class citizenship as a language. Native iOS apps for example may be written for the most part in javascript using the native 'bridge' that makes it possible to "JavaScript scripts from Objective-C or Swift code, to access values defined in or calculated in JavaScript, and to make native objects, methods, or functions accessible to JavaScript" \cite{apple}. The extent to which Javascript is embedded within today's technology means there is always likely to be some device that can run Javscript to hand.

\paragraph{Longevity} The ubiquity of Javascript presupposes that the language will be still be usable many years in the future. Its longevity is being aided by the availability of 'compile-to-javascript'. These languages use Javascript as "JavaScript is an assembly language" \cite{hanselman}. Meijer goes further to say that "the browser can execute [Javascript], but no human should really care what’s there." As such, it is unlikely that the role of Javascript will be diminished any time soon.

\paragraph{Precedence} Javascript is used as a target language for other technological preservation projects. The 'Javascript MESS' project is a movement to produce an emulator for 'hundreds' of machine types in the browser. The overall aim 

\subsection{Javascript as a Compile Target}

Javascript is not only well suited on paper to being a compile target of other languages. There is also plenty of precedent. A list of compile-to-javascript languages is maintained in the wiki of a popular language called CoffeeScript \ref{compiletojs}. CoffeeScript is one of the most well-known compile-to-javscript implementation. It does not offer vastly different programming paradigms to regular javascript apart from its use of classical inhertitance as opposed to than Javascript's. Rather, the language offers 'syntactic sugar' to make writing succinct javascript easier. The language has been validated by many companies including GitHub as a viable programming language by using it for some of their big projects \ref{csusage}.

The motivations for the many compile-to-javascript languages follow many of the justifications that have been mentioned.


\subsection{Design of other javascript compilers}

A broad set of tooling has been developed to aid the implementation of javascript compilers. The CoffeeScript compiler uses a parser generator called 'Jison'. 'Jison' takes a grammar and produces a parser that will accept a language. It takes the leg work out of writing parsers. The approach it takes is that of 

- historical context
- talk about how Salgol was used
- current status
- history of javascript
- why t makes sense
- problems with javascript
- performance of javascript


\section{Requirements specification}
% Capturing the properties the software solution must have in the form of requirements specification. You may wish to specify different types of requirements and given them priorities if applicable.

The original project aim was to devlop a way for S-Algol to run in a web browser. The focus was 

-  write whole project in javasciprt

\section{Software engineering process}
% The development approach taken and justification for its adoption.

\subsection{Tool Usage}

Before starting programming it was necessary to choose the tools that should be used. Some were straightforward, others required some experimentation.

\paragraph{GIT} is used for version control. This is the currency of modern open source projects. Since one the targets of the proejct is to release the code for access by others, it makes sense to use GIT to manage the software versions.

\paragraph{NPM} is used for package management. This is the most popular Javascript dependency manager and has the best support from node.

\paragraph{TypeScript} is used as the principal development language. The TypeScript project homepage states that "TypeScript is a typed super-set of Javascript that compiles to plain Javascript." \cite{typescript}. This means that any valid Javascript is valid TypeScript but not vice versa.

The extensions within typescript allow a programmer to give variables and functions explicit types. It also allows classical styles of inheritance as a substitute for Javascript's prototype-based inheritance. These permit better static checking of the code since TypeScript has enough information to check whether functions and objects are being used properly within their scope.

This compiler-assistance is particularly useful when implementing a compiler. This is because a common pattern is to tie features of a language's grammar to objects within a language. Abstract and concrete syntax trees may be built up of the these objects. By explicitly defining the objects in a statically typed manner, it is never possible to access the wrong field of an object. In this project, there are over nine hundred classes to define the concrete syntax of S-algol. It would be impossible a human to remember all these classes and their field names. Fortunately, the WebStorm IDE has excellent TypeScript support and will automatically suggest the fields names.

There is no performance penalty of TypeScript since all type information is discarded at compile time, leaving plain Javascript.

A further advantage of using TypeScript is that it is a very modern languages and provides and excellent point of comparison with S-algol and the progress that programming languages have made over the last 35 years. 
\section{Design}
% Indicating the structure of the system, with particular focus on main ideas of the design, unusual design features, etc.


\subsection{Compiler Design Options}

The original S-algol compiler was designed as a single-pass, recursive descent compiler. This design contrasts with multi-pass compilers.

A single-pass compiler performs all the necessary steps including lexing, parsing, type checking and code generation in one pass of the code. Procedures are designed to handle each production of the concrete syntax. Within these functions, a series of statements consume the input programme in an appropriate manner. Errors will be reported wherever an input symbol is not as expected. When a terminal symbol is expected a set of statements will read the next characters, check that they represent the correct symbol and perform appropriate extra steps such as type checking and code generation. When a non-terminal is expected, a call is made to the function that is designed to handle the expected non-terminal.

A multi-pass compiler may work in a similar way in parts but it does not perform all compiler stages in one pass. Instead, it abstracts compiler stages into separate passes and passes some representation of a program between these stages. This is called an intermediate representation, they are often trees of objects. Each pass traverses the intermediate representation as appropriate and passes on the results to the next stage.

Time complexities of single and multi-pass compilers are exactly the same since both a single-pass compiler must traverse a program input once and a multi-pass compiler must pass it a n number of times where n is the number of passes. A single pass compiler however will often benefit from better performance this constant factor is minimised.

(TODO: maybe not that different given input/output) Space complexities of single and multi-pass compilers will be different. Both methods operate on syntax trees which must necessarily have a size that is proportional to the input code. Single pass compilers however, use their call-stack to represent a depth-first traversal of the tree and as such only will use an amount of memory proportional to the greatest depth of the tree. This might be a significant saving, especially given the original platform of the S-algol compiler which was many thousands of times less powerful than today's machines.

Single-pass compilers have limited capabilities in comparison to multi-pass compilers. Single pass compilers lack the ability to check code in relation to code it has not seen yet. For example, they cannot check that a function call is correct if the function is called before it is declared. This is why ALGOL languages often include 'forward' declarations that inform the compiler in advance the name of a function and its type signature. Morrison points out that this is "awkward when recursive procedure definitions are involved" since a function must be available in scope so it can reference itself. The solution to this in S-algol is that "the identifier comes into scope after the parameter list has been specified allowing procedures to call themselves" \cite{morrison1979development}. However, it is trivial to infer forward declarations in a multi-pass compiler since it does type checking after all the code has been seen.

A subjective advantage of multi-pass compiler is that it offers a considerably better structure for drawing abstraction between parts of a compiler. A type-checker might, for example, be an optional component that can be switched in and out for performance reasons. Similarly, if a different target language is chosen, it would be simple to swap the pass that deals with code generation for a different one.

Design patterns can also make the multi-pass compiler highly abstract. Norman Neff describes how the visitor pattern can be used to abstract the traversal mechanism of a collection of referenced objects (such as a syntax tree) from the operations on those objects. With reference to compiler design, Neff claims that "the visitor pattern gives the abstract syntax tree responsibility for defining a traversal sequence to be followed by all visitors." \cite{neff1999oo}. Neff points out however that the visitor pattern is limited to fixed orders of traversal, it is only useful if a programmer is doing many traversals using a fixed ordering such as depth-first or breadth-first traversal. 

The visitor pattern gives the abstract syntax tree responsibility for defining a traversal sequence to be followed by all visitors.

\subsection{Code Target}

The original implementation of the S-algol compiler converted S-algol input to 'S-code'. This S-code could then be executed on an S-code machine. This is very similar to Java's model: Java code is compiled to bytecode and run on a JVM. The advantage of this is that such machines maybe be implemented for arbitrary hardware and operating system targets such that code in Java or S-algol could be run on any platform without changing the compiler implementation.

It would be possible to implement a similar approach for this compiler implementation. The compiler could emit S-code and an S-code machine could be implemented in javascript.

The advantage of the S-code based approach would be very precise control over execution. The S-code machine would be able to execute instructions atomically and would have full access to the program state. As such, implementation of debuggers and other runtime tools would be trivial. Furthermore, some subtle implementation details of S-Algol could be implemented in the machine rather than the compiler. By compiling straight to javascript, this control is somewhat lost to the javascript virtual machine: all code outputted by the S-Algol compiler must precicisely represent S-Algol paradigms in terms of javascript paradigms.

The advantage of compiling directly to javascript would be a smaller, simpler project. It would allow the features that are already built into most javascript virtual machines to be used such as debugging. It is also likely to offer better performance than an S-code. This is becuase many features would duplicated between the JavaScript machine and the S-code machine. For example, they would both require garbage collection, stack management and heap management.

Another key advantage of cutting out the S-code component is that the output code can work inline with any external javascript or libraries. The javascript ecosystem has a very established set of libraries and build tools available. 

The simplicity of the direct-to-javascript approach as opposed to attempting to implement the S-code machine was the main justification choosing it for this project.

\subsection{Final Compiler Design}

The final architecture for the project is a multi-pass implementation. The performance implications of this architecture seemed to be negligible in comparison to the benefits of more abstraction. The advantages of being able to add or remove parts of the compiler arbitrarily would also be useful in case the complete solution was not completed by the end of the project. Furthermore, since the target language is Javascript, not a bytecode, it might be necessary to output symbols not strictly in the order of parsing which would be easier to do given a full intermediate representation.

The initial implementation involved hand-writing the recursive descent parser stage. This stage was designed to accept a string of symbols from a separate lexer and produce and abstract syntax tree to represent the input code. It would also detect context-free errors in the grammar. After a partial implementation of this, it was clear that the approach was problematic.

First of all, the process of writing functions to represent syntax is formulaic. The structure of the recursive descent was more or less a direct mapping from the syntax notation to functions. The corrolary of this was that it was easy to be inconsistent and cause confusion, especially with naming conventions and with the design of the objects into which the language was being parsed. It is not clear, nor semantically obvious whether the recursive grammar fragment,

<foo> ::= bar<foo> | bar;

should be represented as

public class xs {
	bars: string[];
}

or as 

public class xs {
	bar: string;
	xs: xs;
}

Furthermore, should the classes have constructors to initialise the fields? "Modern Compiler Implementation in Java Second Edition" provides a good set of conventions (\ref{fig:classMapping}) for doing this mapping which settles the consistency issue. 


\begin{figure}
\begin{enumerate}
\item Trees are described by a grammar.
\item A tree is described by one or more abstract classes, each corresponding to a
symbol in the grammar.
\item Each abstract class is extended by one or more subclasses, one for each gram-
mar rule.
\item For each nontrivial symbol in the right-hand side of a rule, there will be one field in the corresponding class. (A trivial symbol is a punctuation symbol such as the semicolon in CompoundStm.)
\item Every class will have a constructor function that initializes all the fields.
\item Data structures are initialized when they are created (by the constructor func-
tions), and are never modified after that (until they are eventually discarded).
\end{enumerate}
\caption{Conventions for representing tree data structures in Java. \cite{11270520020101}}
\label{classMapping}
\end{figure}

Another point of difficulty was the process of recognising which production could be applied in a given situation. Take for example the simple S-algol program that assigns a to the expression "1".

let a = 1?

The entry production for S-algol is <program>. The following productions are the subset required to parse the given section of S-algol:

\begin{lstlisting}[caption={TODO},label={lst:fixedclauseprod}]
<program> \&::= <sequence>?
<sequence> \&::= <declaration>[;<sequence>] | <clause>[;<sequence>]
<declaration> \&::= <let_decl> | <structure_decl> | <proc_decl> | <forward>
<let_decl> \&::= let <identifier><init_op><clause>
\end{lstlisting}

The difficulty parsing this program however, is recognising which productions apply in these cases. The following code represents a fragment of a recursive descent compiler that might being to handle the parsing of a let declaration.

\begin{lstlisting}[caption={TODO},label={lst:fixedclauseprod},language=javascript]
var input = ['let', 'a', '=', '1'];

function program(): Program {
	return new Program(sequence());
}

function sequence(): Sequence {
	if (isDeclaration(input[0])) {
		return new Sequence(declaration(), sequence());

	} else if (isClause(input[0])) {
		return new Sequence(clause(), sequence());

	}
}
\end{lstlisting}


The implementation difficulty with this code is the implementation of the functions, 'isDeclaration' and 'isClause'. While it is easy to see for isolated incidences which productions should be used to parse a snippet of code, in the general case, it is more complex.

It might be possible to implement 'isDeclaration' as follows:

\begin{lstlisting}[caption={TODO},label={lst:fixedclauseprod},language=javascript]
function isDeclaration(): boolean {
	return input[0] === "let";
}
\end{lstlisting}


This seems obviously correct, because we know that if the leading symbol is currently equal to "let", we obviously are dealing with a declaration. But the real definition of 'isDeclaration' should be as follows.

\begin{lstlisting}[caption={TODO},label={lst:fixedclauseprod},language=javascript]
function isDeclaration(): boolean {
	return input[0] === "let" || input[0] === "forward" || input[0] === "procedure" || input[0] === "let";
}
\end{lstlisting}


It seems like it is necessary to write a recognition function for every production which could end up being very time consuming especially for some 'deep' productions.

All these issues appear to be intellectually trivial; they are easy to understand and solve algorithmically but hard to do by hand. The issues are also very restrictive, such that if the implementation uses one particular approach, it would be very time consuming to change it later on.

It seemed obvious that at least the parser stage should be generated programmatically from the syntax notation. This would have the following advantages:

\begin{enumerate}
\item Implementation of parser generator would take equal or less time to hand writing parser.
\item The generated representation of the concrete syntax would be consistent.
\item Changes to the conventions explored above would be trivial.
\end{enumerate}

Furthermore, an object-based representation of the grammar syntax would allow production recognisers such as 'isDeclaration' to be generated programatically.


\section{Implementation}
% How the implementation was done and tested, with particular focus on important / novel algorithms and/or data structures, unusual implementation decisions, novel user interface features, etc.

\subsection{Meta-Compiler Design}

The decision to programmatically generate the S-Algol compiler meant that the parser implementation focus had to be changed. The first aspect of the meta-compiler was to implement a small compiler chain for the grammar. This is a simple implementation since the grammar has a simple syntax.  

The meta-compiler represents the syntax using objects. A production such as 

\begin{lstlisting}[caption={TODO},label={lst:fixedclauseprod}]
<let_decl> ::= let <identifier><init_op><clause>
\end{lstlisting}


is represented using the following object structure

% var grammar = {
% 	...
% 	"<let_decl>" : { 
% 		productions: [
% 			[{value: "let"}, {value: "<identifier>"}, {value: "<init_op>"}, {value: "<clause>"}]
% 		]
% 	}
% 	...
% }

Given this object, it is possible to algorithmically solve the problems encountered whilst hand-writing the parser.

The first thing that was implemented was the production recogniser. This is a function that takes the current expected production (initially, always '\lstinline{<program>}') and the current first value in the input array then outputs which production will parse the current input; just as 'isDeclaration' did. This recogniser uses a pre-computed table that is generated from the grammar. A subset of the table is displayed in Figure \ref{fig:recogniserobj}. Its utility can be demonstrated with an example. A program \lstinline{let a = 1?} is assumed to be a grammar fragment of type \lstinline{<program>}. The leading symbol, "let", is then looked up in the table for \<program\>. In this table, "let" maps to \<sequence\>. This identifies the beginning of the list to be of type \<sequence\>. It is then possible to look up "let" in the \<sequence\> table, to get \<declaration\>. This continues until the fragment is recognised as a \<let_decl\>. Here, the mapping gives a production that starts with 'let'. This allows the parser to consume the 'let' symbol and begin to parse the \<identifier\> in the same way.

\begin{figure}[htbp]
  \centering
  \includesvg{image}
  \caption{Recogniser table subset}
  \label{fig:recogniserobj}
\end{figure}

The algorithm represented by this example shows how the recogniser table can be used to effectively 'configure' a generic (and very simple) parser. Details of this parser will be discussed in a later section.

When planning the compiler implementation initially, this approach seemed a fool-proof way to get a correct parser up and running. However, unexpected problems were encountered with the implementation.

The first of these problems occurs when a production is not LL(1). LL(k) is a measure of how many symbols it takes to recognise a production. The implementation thus far is contingent on the premise that all productions can be recognised by their first symbol. This is mostly true for the language except for a few cases. One of these cases exists in the <clause> production, part of which is show in Listing \ref{lst:clauseprod}. 

\begin{lstlisting}[caption={Fragment of the <clause> production},label={lst:clauseprod}]
<clause> ::=
if<clause>do<clause> |
if<clause>then<clause>else<clause> |
...
\end{lstlisting}

Listing \ref{lst:clauseprod} might produce a recogniser table containing the fragment shown in Figure \ref{fig:incorrectrecogniserobj}. 

\begin{figure}[htbp]
  \centering
  \includesvg{image}
  \caption{Clause recogniser table subset}
  \label{fig:incorrectrecogniserobj}
\end{figure}

The problem is obvious, it is impossible to tell whether to expect an 'if do' clause or an 'if then' clause simply by looking at the if symbol. One way to fix this problem is to defer the decision until 'do' or 'then' are encountered. This fix is problematic because it compromises the simplicity of possible compiler implementations. An alternative way to fix this issue is to alter the grammar. Listing \ref{lst:fixedclauseprod} shows how it is possible to alter the grammar in such a way to fix the issue and still accept the same set of strings.

\begin{lstlisting}[caption={LL(1) <clause> production},label={lst:fixedclauseprod}]
<if_tail> ::=
do<clause> |
then<clause>else<clause>

<clause> ::=
if<clause><if_tail> |
...
\end{lstlisting}

The next problem with generating an unambiguous recogniser table is that of left recursion.  

\begin{lstlisting}[caption={Fragment of the <clause> production},label={lst:clauseprod}]
      
<expression> ::= <exp1>[or<exp1>]*
<exp1> ::= <exp2>[and<exp2>]*
<exp2> ::= [~]<exp3>[<rel_op><exp3>]
<exp3> ::= <exp4>[<add_op><exp4>]*
<exp4> ::= <exp5>[<mult_op><exp5>]*
<exp5> ::= [<add_op>]<exp6>
<exp6> ::= 
...
<expression>(<clause><bar><clause>) |
<expression>(<dereference>) | 
...
\end{lstlisting}


\subsection{Grammar Transformations}

After the implementation of the meta-compiler, the grammar was available as an object. The overall compiler design was to use this object to parse input. 

\subsection{Implementing S-Algol Features}

Despite many similarities, some parts of S-Algol do not have clear equivalent implementations in javascript. One of these differences is that conditional statements and loops may act as expressions. The may yield a result which can be applied to a variable or argument. Listing \ref{lst:condass} is an example of a trivial S-Algol program that assigns 1 to variable a.

\begin{lstlisting}[caption={S-Algol conditional assignment},label={lst:condass}]
let a = if true then 1 else 2?
\end{lstlisting}

An equivalent Javascript program might use the javascript ternary operator as shown in listing \ref{lst:jscondass}

\begin{lstlisting}[caption={Javascript conditional assignment},label={lst:jscondass}, language=javascript]
var a = true ? 1 : 2;
\end{lstlisting}

This might be a fairly good mapping however the javascript ternary operator does not handle more complicated expressions. The code in listing \ref{lst:complexcondass} represents a marginally more complicated statement. Here, the result of the if expression is simply 34, however, two statements have yielded this number rather than just 1 in the previous expression.

\begin{lstlisting}[caption={More complicated S-Algol conditional assignment},label={lst:complexcondass}]
let a = if true then {let a = 34; a} else 2?
\end{lstlisting}

There is no perfect equivalent in Javascript: it is not possible to add a block statement to a ternary operation. However, it is possible to use a function instead. This makes sense since a function may be defined as an abstraction over a set of statements; a block statement is the same except it is not re-useable, nor can it accept arguments, it rather inherits the scope of its parent block. As such, the javascript program in listing \ref{lst:jsfncondass} might be an appropriate equivalent to the S-algol in \ref{lst:complexcondass}.

\begin{lstlisting}[caption={Javascript conditional assignment using a function},label={lst:jsfncondass}, language=javascript]
function temp() {
    var a = 34;
    return a;
}

var a = true ? temp() : 2;
\end{lstlisting}

Since this 'temp' function will necessarily only be used once, it might be better design to actually remove it from the namespace altogether since a procedure with the same name may be accidentally be overwritten. This is possible with a some syntactic sugar available in Javascript shown in \ref{lst:jsfncondass}. An anonymous function is declared and called in a single expression. Note the application of the anonymous function is triggered by the parentheses on line \ref{line:application}.

\begin{lstlisting}[caption={Javascript conditional assignment using a function},label={lst:jsfncondass}, language=javascript, escapechar="|"]
var a = true ? function() {
    var a = 34;
    return a;
}() : 2; |\label{line:application}|
\end{lstlisting}

There is an advantagous side effect to using javascript functions to express S-Algol blocks. This lies in javascript's scoping paradigm. In the S-algol spec, Morisson describes the languages very simple scoping system: "the scope of an identifier starts immediately after the declaration and continues up to the next unmatched } or 'end'." \ref{TODO} As such, S-algol may have indefinitely-many scopes in a single program. ES5 Javascript's two scopes are decribed in a Microsoft reference document as "global and local. A variable that is declared outside a function definition is a global variable, and its value is accessible and modifiable throughout your program. A variable that is declared inside a function definition is local. It is created and destroyed every time the function is executed, and it cannot be accessed by any code outside the function." \ref{https://msdn.microsoft.com/en-us/library/bzt2dkta(v=vs.94).aspx}.

In this S-Algol compiler implementation, scope checking is executed statically so it is not necessary in most cases to ensure that the scope is verified. However, there are some cases where the more-permissive javascript scope will cause interference between variables. For example the S-Algol programme in Listing \ref{lst:scoping} would be expected to print 5 then 1.

\begin{lstlisting}[caption={S-Algol scoping},label={lst:scoping}, escapechar="|"]
let a = 1;

if true then {
	let a = 5; |\label{line:decl}|
	write a;
}
write a?
\end{lstlisting}

The naïvely-compiled javascript program in Listing \ref{lst:jsnaive} would print 5 then 5. This is because the if block is assigning variables in the global scope whereas in S-algol, the if block creates a new scope. (It is important to note that child blocks in S-algol do inherit scope from their parents such that if Line \ref{line:decl} were removed from Listing \ref{lst:scoping}, the program would simply print 1 then 1.)

\begin{lstlisting}[caption={Javascript scoping},label={lst:jsnaive}, language=javascript, escapechar="|"]
var a = 1;

if (true) {
	var a = 5;
	console.log(a);
}

console.log(a);
\end{lstlisting}

To make the javscript program act more like S-Algol, it is possible to take advantage of the function-local variable features of javascript. The Javascript code in Listing \ref{lst:betterscope} prints 5 then 1, just as was expected from the S-Algol program in Listing \ref{lst:scoping}. Furthermore, the inner scope inherits scope from its parents just like S-Algol scopes. As such, you can delete \ref{line:decl} from Listing \ref{lst:scoping} and the program will print 1 then 1;

\begin{lstlisting}[caption={S-Algol-like Javascript scoping},label={lst:betterscope}, language=javascript, escapechar="|"]
var a = 1;

(function() {
	if (true) {
		var a = 5; |\label{line:jsdecl}|
		console.log(a);
	}
})();

console.log(a);
\end{lstlisting}

In conclusion, single-use anonymous functions provide S-Algol-like scoping and allow abstraction over block statements such that they can be used as expressions.


ES6 has a new block-scoping syntax but this can be simmul


\subsection{Implementing 'Abort'}

In S-Algol, the abort keyword stops exectuion permanently. There are a few candidates for replication of abort in javascript. In the node javascript, the environment object called 'process' has a member function called 'exit' which behaves like the posix exit function. It allows a node program to end abruptly with a return value. This does not unfortunately work in the browser. Javascript also has a GOTO-like syntax called a label that allows the execution flow to jump between line numbers, however, this does not allow exit from functions so cannot be used to guaruntee that a program is stopped from anywhere within the control flow.

This S-Algol implementation uses the Javascript exception handling to allow halt execution. I

\begin{lstlisting}[caption={S-Algol-like Javascript scoping},label={lst:betterscope}, language=javascript, escapechar="|"]
function recurse(x) {
	if (x == 4) return;
	recurse(x+!)
}
console.log(a);
\end{lstlisting}


\subsection{Language specification}

A major challenge of this project was something of an archealogical problem. The S-Algol language was first designed and implemented nearly 40 years before the start of this project. This fact, coupled with its modest adoption outside of St Andrews, means that there is a limited set of documentation available. The sources available for reference were:

\begin{enumerate}
\item "S-algol Reference Manual" \cite{TODO}
\item "ON THE DEVELOPMENT OF ALGOL" \cite{TODO}
\item "Recursive Descent" \cite{TODO}
\item "Programming in S-Algol" \cite{TODO}
\item A C implementation of the S-algol compiler. \appendix{TODO: maybe?}
\item An S-Algol impementation of the S-algol compiler. \appendix{TODO: maybe?}
\end{enumerate}

Within these sources are 3 different different grammar specififications. With a reasonably thorough analysis, these grammar specifications are roughly analogous. "S-algol Reference Manual" defines a context-free grammar that is the main point-of-reference for this project. "Programming in S-Algol" defines a context-sensitive two-level grammar. This is a variation of a Van Wijngaarden grammar that precisely defines all possible strings accepted by the S-Algol language including how types may be combined through operations \cite{TODO}. Initially it seemed as though this Van Wijngaarden would be a good target for the parser generator since it might be able to find type errors as well as syntax errors. Research however revealed that in the general case, it is an undeciadable problem as to whether a string fulfills two-level grammars \cite{TODO}. It may be the case that the S-Algol specification is a case that does happen to be decideable; however, it seemed to make more sense to decouple the grammar-checking and type-checking in the interests of good software engineering practice. The final formal specification, is found in the Morrison's book, "Recursive Descent". This appears to be a subset of the context-free grammar found in "S-algol Reference Manual" that does not include the first-class pixel manipulation features found in the latter.

A context-free grammar is a powerful first stage in recognising whether a string is grammatically valid. A string of symbols may be checked a against a grammar and be verified as to whether they are correct or not. A tree is then produced that has the input symbol as leaves and other nodes that represent the significance of each part of the grammar.

However, the problem with these grammars is that they can be ambiguous. Ambiguity in context free grammars mean that the same input string may be able to satisy a grammar by producing two different syntax trees. This can be problematic since two different syntax trees can have different semantic implications. The consequence of this is that given the same context-free grammar and the rest of the compiler toolchain, two compiler-writers can write a parser that causes the program to be executed significantly differently. A classic example of this problem is the dangling else issue found in most ALGOL languages. This problem happens to be present in S-Algol. Listing \ref{lst:dangle} contains an example of such a case. It has been indented to make it look like nothing should be printed: clearly, '2 < 1' evaluates to false and, as such lines \ref{line:dang1} to \ref{line:dang2} will never be executed.

\begin{lstlisting}[caption={S-Algol dangling else},label={lst:dangle}, escapechar="|"]
if 2 < 1

	then if true	|\label{line:dang1}|
		then {write 1}
		else {write 2}; |\label{line:dang2}|
\end{lstlisting}

However, Listing \ref{lst:danglealternative} shows that there is an alternative way of understanding the exact same input string. This example uses exactly the same input string as Listing \ref{lst:dangle} but the indentation has been changed to make it clear that the else condition in line \ref{line:dang2a} is actually intended to complete the if statement that is established in line \ref{line:dang1a}.

\begin{lstlisting}[caption={S-Algol dangling else alternative parse},label={lst:danglealternative}, escapechar="|"]
if 2 < 1 |\label{line:dang1a}|
	then if true 
		then {write 1}
else {write 2}; c
\end{lstlisting}

In some languages, this ambiguity is resolved by explicit characters that show where an if statement ends. However, in languages where there are no such delimeters, further definition is required to make an effective parse.

Unfortunately, S-Algol documentation has no such clarification on handling of the dangling else problem so the original parser implementation must be the first point of reference. Listing \ref{lst:ifclause} contains the definition of the recursive descent procedure that parses 'if' statments. Line \ref{line:clauseparse} makes a call to the procedure that handles parsing of clauses as such, the dangling else will be syntactically applied to the inner most if statement.

\begin{lstlisting}[caption={S-Algol compiler implementation of parsing an 'if' statement},label={lst:ifclause}, escapechar="|"]
procedure if.clause( -> pntr )
begin
     next.sy
     match( BOOL,clause )
     let l = jumpf( newlab )
     if have( do.sy ) then
     begin
          match( VOID,clause )
          setlab( l )
          VOID
     end else
     begin
          mustbe( then.sy )
          let t = clause
          let m = fjump( newlab )
          dec.stack( t )
          setlab( l )
          mustbe( else.sy )
          let t1 = clause |\label{line:clauseparse}|
          if eq2( INT,t ) and eq2( REAL,t1 ) then
          begin
               let n = fjump( newlab )
               setlab( m )
               float.op( 1 ) ; dec.stack( INT )
               setlab( n )
               REAL
          end else { match( t,t1 ) ; setlab( m ) ; t }
     end
end
\end{lstlisting}

This is a clear example of how the definition of a language's grammar cannot solely lie in its context-free grammar. Rather, it must be specified.

\subsection{Lexer}

The role of a lexer in a compiler is to break up a continuous input string into lexical symbols that can be accepted by the parser. As such a lexer does not necessarily need to respect the grammar of a language. This assumption actually diverges from the original S-Algol implementation. The single-pass nature of the original implementation means that the input string is 'lexed' in the same recursive descent as all of the other language operations as such, the program 'knows' a subest of symbols that should be expected to be lexed. For example, it the program is currently executing the function that handles let declarations, it knows to first expect the characters 'let' and nothing else; then the next string of characters will be a sequence of valid identifier characters. A marginal advantage of this method is that it might save a bit of computation given this knowledge of whats coming next since only a few possibilities need checking. However, it adds bulk to the parsing stage of the compiler and since the overall design of this new implementation is to emphasise separation of concerns rather than efficiency, it makes sense to implement a simple lexer and separate parser than to add a lexer to the already-complex parser.

Since the lexer should be able to lex input from any point within a program and does not have grammatical understanding of the input, there are some considerations that must be made to ensure the correct symbols are lexed. For example, when a lexer sees 'let', it should produce a single LET symbol; but when a lexer sees 'foo', it should produce the three symbols F, O, O. As such, symbols can be broken into priority classes. It is common practice for a language to reserve a set of keywords that may not be used as identifiers such that \lstinline{let let = 1?} might be an invalid program.

The basic algorithm implemented by this lexer is to try to recognise some class of symbol from the head of the input and if a match is found, consume that match from the head of the input and produce apropriate symbols. In Typescript, it was most appropriate to implement these symbols using the enum structure. To aid the implementation of this further, this enum is generated as part of the meta-compiler TODO: expand.

Each class of language is represented by a regular expression. TODO: maybe cite the java compiler book. 
Listing \ref{lst:keywordsregex} shows the regular expression that is used to recognise keywords. It is checked first. It is roughly separable into three parts.

The initial character \lstinline{^} asserts that the following regular expression should only match if it matches at the start of the line. This is important for efficiency and general function of the lexer. It is useless to recognise the string '; let a = 1;' as starting with a LET symbol because it does not.

The body of Listing \ref{lst:keywordsregex} contains and enumeration of all the possible keywords (these are selected from the list of the language's terminals that is generated from the meta-compiler). Full-stop literal characters are escaped since they are usually wild cards in regular expressions. An important consideration of the body of the regular expression is that the keywords are in reverse order of length. This means that if two keywords have the same beginning characters, the longest one will always match. For example, the javascript expressions \lstinline{"isnt".match(/^(is|isnt)/)} will incorrectly match the front of the input as starting with an IS symbol whereas \lstinline{"isnt".match(/^(isnt|is)/)} will correctly match the input string as starting with an ISNT symbol.

The final part of this regex is a negative lookahed \lstinline{(?![a-zA-Z0-9.])}. This is a precaution that checks the front of the input is not an identifier that starts with a keyword. It seems a sensible precaution in a language to prevent keywords being used as identifiers but potentially lazy on the part of the language implementor to disallow any identifier beginning with a keyword. The negative lookahead checks that the character immediately after the keyword is not part of an identifier. If it is, no match is made by this regular expression. As such, this compiler accepts 'let letitia = 1?' as a lexically and grammatically correct program that assigns 1 to variable letitia. Without the negative lookahead, this programme would not be acceptable.

\begin{lstlisting}[caption={},label={lst:keywordsregex}, escapechar="|"]
/^(read\.a\.line|structure|procedure|read\.name|read\.byte|default:|out\.byte|nullfile|forward|read\.32|#cpixel|maxreal|epsilon|read\.16|screen|maxint|repeat|#pixel|string|cursor|colour|rotate|out\.32|output|vector|out\.16|write|pixel|reads|readb|readr|image|limit|shift|scale|readi|begin|while|abort|false|peek|true|rand|onto|text|read|case|xnor|nand|from|copy|else|then|real|file|pntr|bool|isnt|end|xor|lwb|and|ror|upb|eof|int|off|nil|for|let|r\.w|i\.w|s\.w|s\.o|s\.i|div|rem|pic|nor|not|on|pi|do|is|by|if|to|of|at|or|in)(?![a-zA-Z0-9.])/
\end{lstlisting}

The next class of symbol is that of the punctuation symbols. The regular expression follows a similar structure. Here, order is important such that '>=' is recognised before '>'. Lookahead is not importatant because they cannot be part of an identifier since identifiers can only start with an 

\begin{lstlisting}[caption={},label={lst:puncregex}, escapechar="|"]
/^(structure\(|:=|::|\+\+|!=|<=|>=|\*|;|:|~|\{|\}|@|=|!|#|\$|%|&|\?|\+|-|\/|<|>|\[|\\|\]|\^|_|`|\||0|\(|\)|,|"|'|\.)/
\end{lstlisting}

The symbols that represent types are mostly just keywords, however, they may be prefixed by an arbitrary number of asterisks and c's. \lstinline{[\*c]*} matches such a prefix however. It would be possible to write a regex that only lexes correct types ie not 'c*c*c*cint' but not 'ccccint' however, this is done by the parser so is an unecessary complexity. Again, the type regex requires a negative lookahead check that it is not trailed by identifier characters such that the identifier of the declaration 'let introduction = 1?' can be correctly lexed.

\begin{lstlisting}[caption={},label={lst:typeregex}, escapechar="|"]
/^[\*c]*(int|real|bool|string|pixel|pic|pntr|file|#pixel|#cpixel)(?![a-zA-Z0-9.])/
\end{lstlisting}

The final and most permissive regular expressions match strings and numbers. Listing \ref{lst:idregex} shows the expression that matches identifier (which must start with an upper or lower case letter but may contain numbers and full stops).

\begin{lstlisting}[caption={},label={lst:idregex}, escapechar="|"]
/^[a-zA-Z][a-zA-Z0-9\.]*/
\end{lstlisting}

Listing \ref{lst:idregex} shows the expression that matches numbers including integers, floats and exponents.

\begin{lstlisting}[caption={},label={lst:numberregex}, escapechar="|"]
 
\end{lstlisting}

\section{Context Sensitive Analysis}

After a lexer and a parser has been implemented, all further development of a programming language lies in static analysis of the code. This includes type checking and scope checking.


\subsection{Implementation Structure of Context-Sensitive Checking}

Most context-sensitive checking requires a pass through the abstract syntax tree. Since the ordering of these passes is generally the same, it makes sense to use the same visitor pattern that was used in the meta-compiler to abstract the analysis of each node in the tree from the traversal mechanism. Using this pattern, a visitor object may be implemented with a set of functions called 'afterVisit<node>' and 'beforeVisit<node>' (where '<node>' is the name of an abstract syntax tree type). This allows a visitor some flexibility in whether it needs to travers the tree 'in-order' (left-to-right) or 'post-order' (right-to-left). For example, to work out the actual return type of a procedure, it may be necessary to visit the procedure after its body has been visited.

More generic functions are also implemented such as 'afterVisitNode' and 'beforeVisitNode' that are called for every tree node visitation. The utility of these functions is demonstrated in Listing \ref{lst:erroroutput} which requires a traversal that touches all syntax nodes and treats them as the same type (since all nodes may have errors).

A further implementation detail that seemed appropriate was to use classes to represent errors. This means that meta-data can be stored within error messages such that they can be made informative. Furthermore, the instantiations of these errors are stored within the abstract syntax objects as an array. This means that if - for example - there is a tpye error on an operation, the error will be stored in the node that represents that operation. It makes sense to keep errors tightly bound to syntax tree node in this way since it maintains an implicit ordering of errors (inline with the flow of the original program) and also allows for simple inspection of nodes for testing.

Given this method of storing errors, a visitor class is implemented to traverse the tree and output error messages to \lstinline{std.err}. Listing \ref{lst:erroroutput} shows the code that prints the errors. It also demonstrates the terseness of the code that can be written using the visitor pattern: most of the complexity of this feature is wrapped up in the \lstinline{visit} function.

\begin{lstlisting}[caption={Error outputting visitor},label={lst:erroroutput}, language=typescript]
export class ErrorOutputting extends SuperVisitor {
    foundErrors = false;

    afterVisitNode(node: A.AbstractSyntaxType) {
        if (node.errors && node.errors.length > 0) {
            this.foundErrors = true;
            for (let error of node.errors) {
                console.error(error.toString());
            }
        }
    }
}
// the visit function comes from a separate module that implements the abstract tree traversal of the visitor pattern
// the abstractSyntaxTree is an S-Algol program in tree form
visit(abstractSyntaxTree, new ErrorOutputting());
\end{lstlisting}

\subsection{Scope Checking}

A basic type of context-sensitive checking involves checking for scope irregularities. This might pick up problems such as a variable, procedure or structure being operated on, applied or initialised when it has not already been declared. \lstinline{let a = b + 1?} is an example of a program that might trigger a scoping error. Here, the variable b is referred to despite the fact that it has not been yet been declared. 

S-Algol has a simple block-scoping mechanism. A \lstinline{\{} or \lstinline{begin} keyword starts a scope that continues until the next unmatched \lstinline{\}} or \lstinline{end}. Any variable declared within a scope is available until the end of the scope and in all child scopes that exist within it.

Listing \ref{lst:correctscope} represents a correctly scoped program. Variable \lstinline{a} is declared and initialised in the outer scope, updated in a child scope and written to std.out. The program will print '2'.

\begin{lstlisting}[caption={Correctly scoped program},label={lst:correctscope}, escapechar="|"]
let a = 1;
if true do { a = 2 };
write a?
\end{lstlisting}

Listing \ref{lst:incorrectscope} represents an incorrectly scoped program. Variable \lstinline{z} is declared within a child scope and an access attempt is made in the parent scope. By the time the access attempt is made, that variable is no longer in scope. 

\begin{lstlisting}[caption={Incorrectly scoped program},label={lst:incorrectscope}, escapechar="|"]
if true do { let z = 3 };
write z?
\end{lstlisting}

In this compiler implemntation, scope-checking has a two fold advantage. Primarily, it helps a programmer catch bugs that they may not have noticed. However, it also a borderline requirement for a correct implmentation. Since javascript is more permissive than S-Algol, an incorrectly-scoped program may fail silently. For example, the incorrectly scoped program in listing \ref{lst:incorrectscope} might be compiled to the Javascript code shown in Listing \ref{lst:incorrectcompilation}. This, when executed will print '3' as a programmer might have expected from the original S-Algol code. However, this is incorrect usage of the language and should not be encouraged. TODO: justify not permitting usage of javascript features.

\begin{lstlisting}[caption={Possible compilation of Listing \ref{lst:incorrectscope}},label={lst:incorrectcompilation}, language=javascript]
if (true) {
	var z = 3;
}
console.log(z);
\end{lstlisting}

The implementation of the scope checking algorithm is fairly straight forward. Before traversal, an empty stack is initialised. The abstract syntax tree is then traversed in-order.

When the program is entered and at every to a scope, a dictionary object is pushed onto the stack. Every declaration of a variable, procedure or structure that is encountered is recorded in the top-most stack object using the identifier as the key and any meta-infrmation as an object value.

The identifier of every variable, procedure or structure access is checked against the objects in the stack from the top to the bottom. If no objects in the stack contain the identifier then it is not available in scope and there is an error.

Whenever a scope is exited, an object is popped from the stack. As such, all variables that were declared in that scope are no longer visible to the scope checker.

\subsection{Type Checking}

Type checking finds problems in a program that are caused by incorrect passing of literals or language features that represent literals. For example, a variable \lstinline{x} may be declared as type a and operated on as though it were some incompatible type b. This represents a type checking issue.

It quickly becomes clear in the implementation that type checking has a very similar mechanism to scope checking. This is because type checking also relies on keeping track of the current variable scope just as much as scoping checking does. However, in the type checking implementation, more detail must be kept about the variable declarations. In this compiler implementation, the actual abstract syntax tree objects of declarations are kept as a values of the objects in the scope stack that represent the current scope and all parent scopes. These abstract syntax tree objects contain all the relevant meta-data about a declaration. For a procedure, this would be its signature and return type; for a variable, its type; and for a structure, its signature. As such, when an application of one of these language features is encountered, it can be checked for correctness based on this meta-data.

To a large extent, type checking is an aid to the programmer rather than the compiler. In most cases, the compiler does not need to know about typing to correctly compile a program. In some cases however, it is necessary. Listing \ref{lst:untypedambiguity} shows such a case. This program uses S-Algol's support of passing procedures as arguments to other procedures. The high-level function called \lstinline{doAdderThenMultiplyBy2} accepts a procedures and a number, executes the function on the number and multiplies the result by 2. However this syntax conflicts with another syntax feature, that is that procedures in S-Algol may be called without use of parenthesise. As such, another understanding of this program might be that \lstinline{addOne} is executed in line \ref{line:exec} and the result is passed into \ref{doAdderThenMultiplyBy2}. Clearly the latter understanding would cause a type error and the former would not but since the two understandings of the program imply very different semantics, types must be analysed to produce correctly output code.

\begin{lstlisting}[caption={},label={lst:untypedambiguity}, escapechar="|"]
procedure addOne(int -> int); {
	a + 1
};

procedure doAdderThenMultiplyBy2((int -> int) adder; int x -> int); {
	adder(x) * 2;
};

let result = doAdderThenMultiplyBy2(addOne, 5); |\label{line:exec}|
write result?
\end{lstlisting}

In a similar vein, 


% let identifierRegex = /^[a-zA-Z][a-zA-Z0-9\.]*/;
% let number = /^(\+|-)?[0-9]+(\.[0-9]+)?(e[0-9]+)?/;
% let punc = new RegExp(
%     `^(${Object.keys(punctuation).sort(sort).map(escape).join('|')})`
% );
% let types = "(int|real|bool|string|pixel|pic|pntr|file|#pixel|#cpixel)(?![a-zA-Z0-9\.])";
% let concType = new RegExp(types);
% let augTypeReg = new RegExp(`^[\\*c]*${types}`);
% let stringReg = /"([ -!#-&(-~]|('")|(''))*"/;



- initial approach, investigation of techniques
- justify choice of typescipt
\subsection{Vector Implementation}

S-Algol arrays are typed, multidimensional and of fixed length. These features are common in array implementations, however the S-Algol array object does have some unusual aspects. Firstly, they have customisable origins. Most languages use zero indexing of arrays, such that the first element of an array is refered to as element 0. S-Algol has customisable indexing. Listing \ref{lst:arrinit} shows three arrays being assigned to variable named a, b and c. The arrays are of type *int and each have a length of 3. The values contained in each are also 1, 2 and 3. The difference between the arrays is that their first element of the array is indexed with each a different number. This number is perscribed by the expression after the '@' symbol. The first element of a has an index of 1, the first of b has an index of 100 and the first of c has an index of -60. The program will print three '1's.

\begin{lstlisting}[caption={Array Initialisation},label={lst:arrinit}, escapechar="|"]
let a = @ 1 of int [1,2,3];
write a(1);

let b = @ 100 of int [1,2,3];
write b(100);

let c = @ 40 - 100 of int [1,2,3];
write c(-60)
?
\end{lstlisting}

This design provides certain problems for the compiler design. Javascript has no such built-in method for customising the index scheme. As such, the index 'offset' must be stored such that it can be used to translate indicies into javascript's zero-indexed array scheme. One possible way to do this would be to wrap arrays in an object that stores the offest and the array values in two fields. Every time a lookup is performed, the offset may be used to translate the lookup value to the correct index in the object. This would work effectively bus the use of objects and arrays together might add confusion to the compiled code. As such, this compiler implementation uses the first value of the array that is compiled to represent the offset. This means that only arrays are being used in the compiler output. The fact that the first element of the javascript array is being used as the index offset is accounted for by adding 1 to the index translation.

\begin{lstlisting}[caption={1-Indexed Array},label={lst:1ind}, escapechar="|"]
let a = @ 1 + 2 of int [1,2,3];
write a(3);
?
\end{lstlisting}

The code in Listing \ref{lst:1ind} compiles to the code in \ref{lst:jsindex}. Line \ref{line:index} shows the storage of the index offset. Line \ref{line:offset} shows the calculation of the offset based in the desired index. This program correctly prints 1.

\begin{lstlisting}[caption={TODO},label={lst:jsindex},language=javascript, escapechar="|"]
var a = [
    1 + 2, |\label{line:index}|
    1,
    2,
    3
];
write(a[1 + (a[0] - 3)]); |\label{line:offset}|
\end{lstlisting}

This also works for multi-dimensional array access. The offsets from every level are simply taken into account.

From the perspective of usability, it is not clear why the decision of customising indexing has been made. It is possible that it is to settle any argumentation over whether arrays should be 0-indexed or in fact 1-indexed TODO find argument about this.

\subsection{Tool Usage}

\section{Ethics}
% Any ethical considerations for the project.
 
- examination of recursive descent 
- justification for not choosing recursive descent directly
    - attempted to write recursive descent by hand
- reference limitations of not choosing recursive descent
- talk about nanopass
 http://www.cs.indiana.edu/~dyb/pubs/nano-jfp.pdf
- argue that it offers better abstraction but perhaps less good performance

 
\section{Evaluation and critical appraisal}
% You should evaluate your own work with respect to your original objectives. You should also critically evaluate your work with respect to related work done by others. You should compare and contrast the project to similar work in the public domain, for example as written about in published papers, or as distributed in software available to you.


- compare compiler performance with other transpilers on comparible compilers
- compare performance of produced code with other transpiled languages

\section{Conclusions}
% You should summarise your project, emphasising your key achievements and significant drawbacks to your work, and discuss future directions your work could be taken in.


\section{Appendices}

Testing summary
% This should describe the steps taken to debug, test, verify or otherwise confirm the correctness of the various modules and their combination.


User manual
 
% Instructions on installing, executing and using the system where appropriate.

Other appendices
% If appropriate, you may include other material in appendices which are not suitable for inclusion in the main body of your report.

\end{document}